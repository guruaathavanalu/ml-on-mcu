{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on MCU - Ex3.2\n",
    "\n",
    "This exercise will introduce you to Keras, one of the most popular frameworks used in Deep Learning.\n",
    "\n",
    "You will train a simple multi-layer perceptron to predict Human Activity from Smartphone Accelerometer and Gyroscope Data.\n",
    "\n",
    "We use a dataset of 3-axial accelerometer signals from an academic experiment on the UC Irvine Machine Learning Repository.\n",
    "\n",
    "The dataset is downloaded in the code snippet below and you can you can also find the description of the dataset [here](https://archive.ics.uci.edu/dataset/341/smartphone+based+recognition+of+human+activities+and+postural+transitions) .\n",
    "\n",
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# If required, download the dataset\n",
    "import requests\n",
    "import os.path\n",
    "import zipfile\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "if (not os.path.isdir('./HAPT Data Set')):\n",
    "    open('./HAPT Data Set.zip', 'wb').write(requests.get(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00341/HAPT%20Data%20Set.zip\", \n",
    "        allow_redirects=True).content)\n",
    "    zipfile.ZipFile('./HAPT Data Set.zip', 'r').extractall('./HAPT Data Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the accelerometer and gyroscope data.\n",
    "We read the feature names from features.txt and the activity labels from activity_labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open('./HAPT Data Set/features.txt') as f:\n",
    "    features = f.read().split()\n",
    "\n",
    "print('There are {} features.'.format(len(features)))\n",
    "    \n",
    "with open('./HAPT Data Set/activity_labels.txt') as f:\n",
    "    activity_labels = f.readlines()\n",
    "\n",
    "activity_df = [x.split() for x in activity_labels]\n",
    "print('There are {} activities.'.format(len(activity_df)))\n",
    "pd.DataFrame(activity_df, columns = ['Activity_id', 'Activity_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are pre-split into training and test sets. Let's load the features x and the labels y, and have a look at a few features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_table('./HAPT Data Set/Train/X_train.txt',\n",
    "             header = None, sep = \" \", names = list(dict.fromkeys(features)))\n",
    "X_train.iloc[:10, :10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_table('./HAPT Data Set/Train/y_train.txt',\n",
    "             header = None, sep = \" \", names = ['Activity_id'])\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_table('./HAPT Data Set/Test/X_test.txt',\n",
    "             header = None, sep = \" \", names = list(dict.fromkeys(features)))\n",
    "y_test = pd.read_table('./HAPT Data Set/Test/y_test.txt',\n",
    "             header = None, sep = \" \", names = ['Activity_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Human Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "\n",
    "# Note: use Tensor Flow backend for Keras as suggested on keras.io:\n",
    "# \"At this time, we recommend that Keras users who use multi-backend Keras with the TensorFlow backend switch to tf.keras in TensorFlow 2.0. tf.keras is better maintained and has better integration with TensorFlow features (eager execution, distribution support and other).\"\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the accelerometer and gyroscope data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and testing sets. (You can take example from ex 1 and 2.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: Keras takes the classes from 0, i.e. if you have classes [1, 2, 3] (as in this case), it will give you an error.\n",
    "# To avoid the error, shift the class labels by -1, i.e. from [1, 2, 3] to [0, 1, 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define batchsize and number of epochs\n",
    "\n",
    "\n",
    "\n",
    "# Declare the sequential model and design your multi-layer perceptron\n",
    "\n",
    "\n",
    "# Compile your model\n",
    "\n",
    "\n",
    "# Train your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# You can use model.summary() to get an overview of your model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Save your model once you are satisfied with it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load your saved model and test on the test data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
